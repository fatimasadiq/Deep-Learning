{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatimasadiq/Deep-Learning/blob/main/Assignment_2_backprop_Fatima.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ea-2waagy1Eu"
      },
      "source": [
        "# 521153S:3, Deep Learning assignment 2: Loss Function, Optimization, Neural Networks, Deep Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkQsGPcBy1Ew"
      },
      "source": [
        "## Outline \n",
        "#### In this assignment, you will learn:\n",
        "* **Neural Network, Deep Neural Network, Loss Function and Optimization**.\n",
        "* Building a one layer NN using numpy to understand the backpropagation.\n",
        "* Gradient check using finite-difference approximation.\n",
        "* Stochatic Gradient Descent (SGD).\n",
        "* Simple hype-parameters tuning methods to improve your NN performance.\n",
        "\n",
        "#### Grading (<span style=\"color:green\">15 points</span>)\n",
        "In this assignment, we are going to learn about **Neural Network, Deep Neural Network, Loss Function and Optimization**. They are very important knowledge you need to know in deep learning.\n",
        "\n",
        "Hints: First of all , make sure you implement the sigmoid, softmax and cross-entropy loss **correctly**. <br>\n",
        "Then, **implement first the weight decay off (is_weight_decay = False) then move on with (is_weight_decay = True)**\n",
        "* **Part 1.** Import libraries, loading and preprocessing the training and testing data.\n",
        "* **Part 2.** Optimize the neural network according to the loss function. (<span style=\"color:green\">12 points</span>)\n",
        "  * 2.1. Construct model in **Fig. 2** (<span style=\"color:green\">4 points</span>) <br>\n",
        "       * 2.1.1 Declare W1 and W2 (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "       * 2.1.2 Implement sigmoid (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "       * 2.1.3 Implement softmax (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "       * 2.1.4 Implement the cross-entropy loss (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "  * 2.2. Implement the forward-pass (<span style=\"color:green\">2.0 point</span>) <br>\n",
        "       * 2.2.1 Foward-pass in training (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "       * 2.2.2 Call cross entropy loss in training (<span style=\"color:green\">0.5 point</span>) <br>\n",
        "       * 2.2.3 Forward-pass in testing (<span style=\"color:green\">0.5 point</span>) <br>\n",
        "  * 2.3. Implement SGD (<span style=\"color:green\">2 point</span>) <br>\n",
        "       * 2.3.1 Velocity (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "       * 2.3.2 Update weights (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "  * 2.4. Derivatives <br>\n",
        "       * Derive equations <br> \n",
        "  * 2.5. Implement the derivatives (<span style=\"color:green\">4.0 points</span>) <br>\n",
        "       * 2.5.1 Implement equation 8 (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "       * 2.5.2 Implement equation 6 (<span style=\"color:green\">0.5 point</span>) <br>\n",
        "       * 2.5.3 Implement equation 10 (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "       * 2.5.4 Implement equation 10+11 (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "       * 2.5.5 Implement equation 7 (<span style=\"color:green\">0.5 point</span>) <br>\n",
        "* **Part 3.** Gradient check using finite-difference approximation. (<span style=\"color:green\">0.5 points</span>) (YOU **DON'T NEED** TO WRITE THE CODE FOR THIS) <br>\n",
        "  * Question: why don't we use FDA to calculate the gradient to update our model? (<span style=\"color:green\">0.5 point</span>) <br>\n",
        "* **Part 4.** Regularization and NN simple tunning. (<span style=\"color:green\">2.5 points</span>) <br>\n",
        "  * 4.1. Applying weight decay. (<span style=\"color:green\">1.5 point</span>) <br>\n",
        "       * There are 3 spots you need to fill, (<span style=\"color:green\">0.5 point</span>) each spot.\n",
        "  * 4.2. Change the number of neurons in the hidden layer and report the performance (<span style=\"color:green\">1 point</span>) <br>\n",
        "\n",
        "#### Environment\n",
        "Python 3, Numpy, matplotlib, sklearn\n",
        "\n",
        "#### Dataset\n",
        "* [**Fashion-MNIST**](https://github.com/zalandoresearch/fashion-mnist)\n",
        "is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits. Using the Fashion-MNIST give you more room to wiggle your experiments.\n",
        "\n",
        "#### Hints\n",
        "* To find the place where you have to insert your solution, hit Crtl + F and search for **TODO:** . You are NOT suppose to modify the codes from other parts.\n",
        "* **Be careful with the shape** of the weights, gradient, .. of your tensor in your implementation. Double check and make sure the shapes are fit for computation, especially matrix multiplication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rW7-GEhy1E1"
      },
      "source": [
        "## Part 1. Import libraries, loading and preprocessing the training and testing data\n",
        "**You don't need to change the code from this part.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66MYH_5Oy1E1"
      },
      "source": [
        "# You will mainly use numpy to construct your NN\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib, time, copy, os, requests, zipfile, sys\n",
        "# Matplotlib to plot the image\n",
        "import matplotlib.pyplot as plt\n",
        "# Off-the-shelf evaluation functions provided by sklearn\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "# Matplotlib predefined 'magic function'. It will include your graphs in your notebook, next to the code\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-vmQo9Zy1E3"
      },
      "source": [
        "### Functions use to download the dataset from google drive\n",
        "The code snipet was taken from [this thread](https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbJxAqAsy1E3"
      },
      "source": [
        "\"\"\"def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWWzYMv85tH7",
        "outputId": "98a600a2-35df-4f54-8197-ceef2f169bdb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VatHFgOC4VDz",
        "outputId": "847c5508-e296-42a2-f720-316fb59b31c4"
      },
      "source": [
        "!unzip gdrive/My\\ Drive/fashion_mnist_npy.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  gdrive/My Drive/fashion_mnist_npy.zip\n",
            "   creating: fashion_mnist_npy/\n",
            "  inflating: __MACOSX/._fashion_mnist_npy  \n",
            "  inflating: fashion_mnist_npy/test_labels.npy  \n",
            "  inflating: __MACOSX/fashion_mnist_npy/._test_labels.npy  \n",
            "  inflating: fashion_mnist_npy/train_labels.npy  \n",
            "  inflating: __MACOSX/fashion_mnist_npy/._train_labels.npy  \n",
            "  inflating: fashion_mnist_npy/train_data.npy  \n",
            "  inflating: __MACOSX/fashion_mnist_npy/._train_data.npy  \n",
            "  inflating: fashion_mnist_npy/test_data.npy  \n",
            "  inflating: __MACOSX/fashion_mnist_npy/._test_data.npy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA4Yp7iDy1E3"
      },
      "source": [
        "### Functions use to pre-process your training/testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE0Q2Qb4y1E3"
      },
      "source": [
        "def reshape_train_data(X):\n",
        "    ''' Input training data has shape (60000, 28, 28)\n",
        "        Input testing data has shape (10000, 28, 28)\n",
        "        where: \n",
        "        60000 is the numbers of input training samples\n",
        "        10000 is the numbers of input testing samples\n",
        "        similar to MNIST, resolution of each sample is 28 x 28\n",
        "    '''\n",
        "    samples, H, W = X.shape\n",
        "    # Reshape input volume to (sample, 784), this mean, your NN input layer will have 784 placeholders\n",
        "    # we scale the RGB values by divide them by 255, this will help improve the training performance\n",
        "    return X.reshape(samples, H * W).T / 255\n",
        "\n",
        "def one_hot_vector(x, num_classes):\n",
        "    # By now, I think you already heard about this so many times\n",
        "    return np.eye(num_classes)[x].T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJoaW4aOy1E4"
      },
      "source": [
        "### We took care of download the data for you.\n",
        "The fashion-MNIST data will be download and store in your **work_dir/data/fashion_mnist_npy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhkGImTcciCY"
      },
      "source": [
        "\"\"\"PATH = './content'\n",
        "if not os.path.exists(PATH):\n",
        "    os.makedirs(PATH)\n",
        "    \n",
        "    file_id = '1DQ2Nf2rY467kyZKOf_CG3Kib5FLv0xQu'\n",
        "    destination = os.path.join(PATH, 'fashion_mnist_npy.zip')\n",
        "    download_file_from_google_drive(file_id, destination)\n",
        "    \n",
        "    with zipfile.ZipFile(destination, 'r') as zip_ref:\n",
        "        zip_ref.extractall(PATH)\n",
        "        \n",
        "    print(\"Data downloaded and extracted!\")\n",
        "    \n",
        "    os.remove(destination)\n",
        "    \n",
        "else:\n",
        "    print(\"Data was already downloaded and extracted!\")\n",
        "\n",
        "PATH = os.path.join(PATH, 'fashion_mnist_npy')\n",
        "\n",
        "# The actual meaning of the label of your classes.\n",
        "# E.g. if a output one-hot vector is [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.], it used to prepresent a Dress\n",
        "label_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IiNI0VT7Vsd"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2Hdtbf-7OSJ"
      },
      "source": [
        "PATH = './content/'\n",
        "PATH = os.path.join(PATH, 'fashion_mnist_npy')\n",
        "\n",
        "\n",
        "label_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRMqnOnky1E4"
      },
      "source": [
        "### Finally, we load and preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "jL_y2TL-y1E5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "a75dc8fc-6bb3-46fa-9b21-6794c0ed6bf9"
      },
      "source": [
        "# Load the training input\n",
        "X_train = np.load(os.path.join(PATH, '/content/fashion_mnist_npy/train_data.npy'))\n",
        "# Load the training labels\n",
        "X_test = np.load(os.path.join(PATH, '/content/fashion_mnist_npy/test_data.npy'))\n",
        "# Load the testing input\n",
        "Y_train = np.load(os.path.join(PATH, '/content/fashion_mnist_npy/train_labels.npy'))\n",
        "# Load the testing labels\n",
        "Y_test = np.load(os.path.join(PATH, '/content/fashion_mnist_npy/test_labels.npy'))\n",
        "\n",
        "# Get the number of classes\n",
        "num_classes = len(label_names)\n",
        "# Get the number of training samples and their resolution for reshape\n",
        "num_trains, HEIGHT, WIDTH = X_train.shape\n",
        "\n",
        "# Reshape the training and testing inputs\n",
        "X_train, X_test = reshape_train_data(X_train), reshape_train_data(X_test)\n",
        "\n",
        "# Create one-hot vector for the training and testing labels\n",
        "Y_train, Y_test = one_hot_vector(Y_train, num_classes), one_hot_vector(Y_test, num_classes)\n",
        "\n",
        "\n",
        "# This part use to randomly load some of the training and testing image and the one-hot vectors for checking\n",
        "fig_train, ax_train = plt.subplots(figsize=(16, 8), nrows=1, ncols=5)\n",
        "fig_train.suptitle(\"Random image from the TRAINING set\", y=0.73, fontsize=16, fontweight='bold')\n",
        "\n",
        "fig_test, ax_test = plt.subplots(figsize=(16, 8), nrows=1, ncols=5)\n",
        "fig_test.suptitle(\"Random image from the TESTING set\", y=0.73, fontsize=16, fontweight='bold')\n",
        "\n",
        "for idx in range(5):\n",
        "    i, j = np.random.randint(num_trains), np.random.randint(X_test.shape[0])\n",
        "    \n",
        "    ax_train[idx].imshow(X_train[:,i].reshape(HEIGHT, WIDTH), cmap = matplotlib.cm.binary)\n",
        "    ax_train[idx].set_title(label_names[np.argmax(Y_train[:,i])] + \"\\n\" + str(Y_train[:,i]))\n",
        "    ax_train[idx].axis('off')\n",
        "    \n",
        "    ax_test[idx].imshow(X_test[:,j].reshape(HEIGHT, WIDTH), cmap = matplotlib.cm.binary)\n",
        "    ax_test[idx].set_title(label_names[np.argmax(Y_test[:,j])] + \"\\n\" + str(Y_test[:,j]))\n",
        "    ax_test[idx].axis('off')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 5 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 5 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf7wn9GNy1E5"
      },
      "source": [
        "## Part 2. Loss function and optimization (<span style=\"color:green\">10 points</span>)\n",
        "#### The fun part start from here.\n",
        "*Definition:* loss function is a function that maps an event or values of one or more variables onto a real number intuitively representing some \"cost\" associated with the event. Loss function (sometime called cost function) is used to calculate the gradient by applying the chain rule, so that we can update the weights (and bias) of our neural network using optimizer such as gradient descent. <br>\n",
        "It could be interpreted as using loss function to calculate the networkâ€™s layers error, in which we calculate the error of the current layer, then pass the weighted error back to the previous layer, and recursively doing this until we travel back to the first hidden layer. At each layer, we update the weights using the derivative of the cost for each weight.\n",
        "\n",
        "Let illustrate this concept using a simple toy example.\n",
        "\n",
        "![toy.png](figs/toy.png)\n",
        "<center> <strong> <font size=\"3\" color=\"blue\"> Figure 1. Toy example of backpropagation </font> </strong> </center>\n",
        "\n",
        "In **Fig. 1** we have a loss function $L$:\n",
        "\\begin{align}\n",
        "L = c \\times d\n",
        "\\end{align}\n",
        "\n",
        "where <br>\n",
        "\n",
        "\\begin{align}\n",
        "c = a + b -5\n",
        "\\end{align}\n",
        "\n",
        "and, <br>\n",
        "\n",
        "\\begin{align}\n",
        "d = b^2 + b -1\n",
        "\\end{align}\n",
        "\n",
        "As illustrated in **Fig. 1**, the equations in the edge show the partial derivation of some functions with respect to their direct variables. For example, $\\frac{\\partial L}{\\partial c}$ is the partial derivative of $L$ with respect to $c$. <br>\n",
        "However, we are actually interested in calculate the derivative of $L$ with respect to $a$ and $b$, which don't directly connected with each other. So, how can we do this? As mentioned earlier, we can do this using the chain-rule so that we can calculate $\\frac{\\partial L}{\\partial a}$ and $\\frac{\\partial L}{\\partial b}$ as:\n",
        "\n",
        "\\begin{align}\n",
        "\\frac{\\partial L}{\\partial a} = \\frac{\\partial L}{\\partial c} \\cdot \\frac{\\partial c}{\\partial a}\n",
        "\\end{align}\n",
        "\n",
        "and, <br>\n",
        "\n",
        "\\begin{align}\n",
        "\\frac{\\partial L}{\\partial b} = \\frac{\\partial L}{\\partial c} \\cdot \\frac{\\partial c}{\\partial b} + \\frac{\\partial L}{\\partial d} \\cdot \\frac{\\partial d}{\\partial b}\n",
        "\\end{align}\n",
        "\n",
        "More importantly, **we can see that $a$ affect $L$ through $c$, and so on**. This concept hold no matter how many hidden layers you have or how complicated your loss will be as long as you use backpropagation to calculate the derivative to update your weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj6q0pNUy1E5"
      },
      "source": [
        "Now, let's get your hand dirty. Let's take a look at the model in **Fig. 2** below. This is the model we are gonna use in this assignment.\n",
        "\n",
        "![NN.png](figs/NN.png)\n",
        "<center> <strong> <font size=\"4\" color=\"blue\"> Figure 2. Structure of our neural network </font> </strong> </center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA7qY2tmy1E6"
      },
      "source": [
        "### Construct model base on **Fig. 2** above (<span style=\"color:green\">4 points</span>)\n",
        "As shown in the **Fig. 2**, our neural network contains two hidden layer (we use 7 and 3 neurons as the  first hidden layer and the second hidden layer default setting respectively) and an output layer. To further simply things, we will not include biases in our model. Be aware that, while the number of neuron in the hidden layer can be abitrary, there must be 10 neurons in the output layer because we want our model to classify images from 10 classes. Based on the **Fig. 2**, you have to construct your network. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17FQ62jgy1E7"
      },
      "source": [
        "# Numbers of input units\n",
        "num_input = X_train.shape[0]\n",
        "# Number of neural in your hidden layer\n",
        "# TODO: modify the number of neurons in the hidden layer\n",
        "num_hidden_1 =7  #150\n",
        "num_hidden_2 =3  #250\n",
        "num_output= num_classes\n",
        "# Construct your neural network from Fig. 2 (1.0 point)\n",
        "# TODO: Random initialize the hidden_1 layer weights (w/o bias)\n",
        "# Hints: use np.random.randn()\n",
        "W1 = np.random.randn(num_hidden_1 , num_input)\n",
        "# TODO: Random initialize the hidden_2 layer weights (w/o bias)\n",
        "# Hints: use np.random.randn()\n",
        "W2 = np.random.randn(num_hidden_2 , num_hidden_1)\n",
        "\n",
        "# TODO: Random initialize the output layer weights (w/o bias)\n",
        "# Hints: use np.random.randn()\n",
        "W3 = np.random.randn(num_output , num_hidden_2)\n",
        "\n",
        "def sigmoid(X):\n",
        "    # TODO: implement Eq. 2 (1.0 point)\n",
        "    # Hints: use np.exp()\n",
        "    #s=1/(1+np.exp(-z))\n",
        "    #return s\n",
        "    return(1/(1 + np.exp(-X)))\n",
        "    \n",
        "\n",
        "def softmax(x):\n",
        "    # TODO: implement Eq. 4 (1.0 point)\n",
        "    # Hints: use np.exp() and np.sum(, axis=0) <- beware of the axis\n",
        "    #e_x = np.exp(X)\n",
        "    #return e_x / e_x.sum(axis = 0 , keepdim=True)\n",
        "    e_x = np.exp(x) \n",
        "\n",
        "    return e_x / np.sum(np.exp(x) ,axis=0)\n",
        "\n",
        "\n",
        "def cross_entropy_loss(Y, Y_pred):\n",
        "    # TODO: implement Eq. 5 (1.0 point)\n",
        "    # Hints: use np.sum(), np.multiply() and np.log()\n",
        "    # At the end, we need to divide by the number of of sample in the training batch e.g. M = Y.shape[1]\n",
        "    #return -sum([Y[i]*log2(Y_pred[i]) for i in range(len(Y))])\n",
        "    m = Y_pred.shape[1]\n",
        "    \n",
        "    cost = (-1/m)*np.sum(np.multiply(Y, np.log(Y_pred)))\n",
        "    #(np.dot(np.log(Y), Y_pred.T) + np.dot(np.log(1-Y), 1-Y_pred.T)) \n",
        "    \n",
        "    return cost\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T26f7V6ky1E7"
      },
      "source": [
        "According to the model in **Fig. 2**, our **forward-propagation** is going to start with the calculation of the output volume $A_1$ for the first hidden layer:\n",
        "\n",
        "\\begin{align}\n",
        "A_1 = \\sigma(Z_1) = \\sigma(W_1 X ) \\tag{1}\n",
        "\\end{align}\n",
        "where $W_1$ is the weights of the first hidden layer, $X$ is the input, and $\\sigma$ is the sigmoid activation where: <br>\n",
        "\\begin{align}\n",
        "\\sigma(x) = \\frac{1}{1 + e^{-x}} \\tag{2}\n",
        "\\end{align}\n",
        "\n",
        "Then, we calculate the hidden volume of the second hidden layer $A_2$ by: <br>\n",
        "\\begin{align}\n",
        "A_2 = \\sigma(Z_2) = \\sigma(W_2 A_1 ) \\tag{3}\n",
        "\\end{align}\n",
        "where $W_2$ is the weights of the second hidden layer.\n",
        "\n",
        "Finally, we calculate the output volume of the output layer $A_3$ by: <br>\n",
        "\\begin{align}\n",
        "A_3 = S(Z_3) = S(W_3 A_2) \\tag{4}\n",
        "\\end{align}\n",
        "\n",
        "In **Eq. 4**, $W_3$ is the weights of the output layer, $A_2$ is the output volume of the last hidden layer, $S$ stands for softmax and defines by: <br>\n",
        "\\begin{align}\n",
        "S(x_i) = \\frac{e^{x_i}}{\\sum_{j=0}^{k} e^{x_j} } \\tag{5}\n",
        "\\end{align}\n",
        "where $i=0,1,..,k$. We use $k$ to represent classes, and $k=9$ in our case.\n",
        "\n",
        "Finally, we compute the loss function using:\n",
        "\n",
        "\\begin{align}\n",
        "L(Y, A_3) = - \\frac{1}{M} \\sum_{k=0}^{M} \\sum_{i=0}^{N} Y_i^{k} log({A_3}_i^{k}) \\tag{6}\n",
        "\\end{align}\n",
        "\n",
        "where $Y$ is the ground truth labels, $N$ is the number of classes, $M$ is the number of samples in the training batch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcn8hSuTy1E7"
      },
      "source": [
        "### Derivative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsNQm6X0y1E7"
      },
      "source": [
        "Using what you learnt in undergraduate school, let's calculate the **backward-propagation** for our model in **Fig. 2**. <br>\n",
        "As mentioned earlier, we are interested in $\\frac{\\partial L}{\\partial W_1}$, $\\frac{\\partial L}{\\partial W_2}$ and $\\frac{\\partial L}{\\partial W_3}$, where: \n",
        "\n",
        "\\begin{align}\n",
        "\\frac{\\partial L}{\\partial W_3} = \\frac{\\partial L}{\\partial A_3} \\cdot \\frac{\\partial A_3}{\\partial Z_3} \\cdot \\frac{\\partial Z_3}{\\partial W_3} \\tag{7}\n",
        "\\end{align}\n",
        "\n",
        ",<br>\n",
        "\n",
        "\\begin{align}\n",
        "\\frac{\\partial L}{\\partial W_2} = \\frac{\\partial L}{\\partial A_3} \\cdot \\frac{\\partial A_3}{\\partial Z_3} \\cdot \\frac{\\partial Z_3}{\\partial A_2} \\cdot \\frac{\\partial A_2}{\\partial Z_2} \\cdot \\frac{\\partial Z_2}{\\partial W_2} \\tag{8}\n",
        "\\end{align}\n",
        "\n",
        "and, <br> \n",
        "\n",
        "\\begin{align}\n",
        "\\frac{\\partial L}{\\partial W_1} = \\frac{\\partial L}{\\partial A_3} \\cdot \\frac{\\partial A_3}{\\partial Z_3} \\cdot \\frac{\\partial Z_3}{\\partial A_2} \\cdot \\frac{\\partial A_2}{\\partial Z_2} \\cdot \\frac{\\partial Z_2} {\\partial A_1} \\cdot \\frac{\\partial A_1}{\\partial Z_1} \\cdot \\frac{\\partial Z_1}{\\partial W_1} \\tag{9}\n",
        "\\end{align}\n",
        " \n",
        "From **Eq. 6** we have: <br>\n",
        "\n",
        "The derivative of $L$ with respect to $Z_3$: \n",
        "\\begin{align}\n",
        "\\frac{\\partial L}{\\partial Z_3} = \\frac{\\partial L}{\\partial A_3} \\cdot \\frac{\\partial A_3}{\\partial Z_3} = A_3 - Y \\tag{10}\n",
        "\\end{align}\n",
        "\n",
        "The derivative of $Z_3$ with respect to $W_3$: \n",
        "\\begin{align}\n",
        "\\frac{\\partial Z_3}{\\partial W_3} = A_2 \\tag{11}\n",
        "\\end{align}\n",
        "\n",
        "From **Eq. 7** we have: <br>\n",
        "\n",
        "The derivative of $L$ with respect to $A_2$: \n",
        "\\begin{align}\n",
        "\\frac{\\partial L}{\\partial A_2} = \\frac{\\partial L}{\\partial Z_3} \\cdot \\frac{\\partial Z_3}{\\partial A_2} = (A_3 - Y) W_3\\tag{12}\n",
        "\\end{align}\n",
        "\n",
        "The derivative of $A_2$ with respect to $Z_2$: \n",
        "\\begin{align}\n",
        "\\frac{\\partial A_2}{\\partial Z_2} = (A_2) (1 - A_2) \\tag{13}\n",
        "\\end{align}\n",
        "\n",
        "The derivative of $Z_2$ with respect to $W_2$: \n",
        "\\begin{align}\n",
        "\\frac{\\partial Z_2}{\\partial W_2} = A_1 \\tag{14}\n",
        "\\end{align}\n",
        "\n",
        "From **Eq. 8** we have: <br>\n",
        "\n",
        "The derivative of $L$ with respect to $A_1$: \n",
        "\\begin{align}\n",
        "\\frac{\\partial L}{\\partial A_1} = \\frac{\\partial L}{\\partial A_2} \\cdot \\frac{\\partial A_2}{\\partial Z_2} \\cdot \\frac{\\partial Z_2}{\\partial A_1} = (A_3 - Y) W_3 (A_2) (1 - A_2) W_2 \\tag{15}\n",
        "\\end{align}\n",
        "\n",
        "The derivative of $A_1$ with respect to $Z_1$: \n",
        "\\begin{align}\n",
        "\\frac{\\partial A_1}{\\partial Z_1} = (A_1) (1 - A_1) \\tag{16}\n",
        "\\end{align}\n",
        "\n",
        "The derivative of $Z_1$ with respect to $W_1$: \n",
        "\\begin{align}\n",
        "\\frac{\\partial Z_1}{\\partial W_1} = X \\tag{17}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4V7vMrPy1E8"
      },
      "source": [
        "## Part. 3 Gradient check using finite-difference approximation. (<span style=\"color:green\">0.5 points</span>)\n",
        "\n",
        "When training deep neural network, there are many things that can go wrong. Until this point, you probably notice that we have been going on and on about the gradient. Why? Because the gradient is very important. Hence, you must making sure that the calculation of your gradient is correct. A correct gradient calculation won't promise your model will converge, but if the calculation was wrong your model will perform very weird. This type of error is hard to debug, so we better prevent it beforehand. <br> \n",
        "To perform the gradient check, we can calculate gradient using the [finite-difference approximation](https://en.wikipedia.org/wiki/Finite_difference) (FDA), and let's call the output of FDA numerical gradients. Then we compare this numerical gradients with the gradient we calculate from taking the derivative. If the differences between them are small enough, we can assume that the gradient was calculated correctly. <br>\n",
        "\n",
        "You probably learnt about FDA in your undergraduate, but to refresh your mind, let's have a simple example to see how FDA works. Assume that we have a function $f(x)$ which <br>\n",
        "\n",
        "\\begin{align}\n",
        "f(x) = \\frac{1}{3} x^3 - \\frac{1}{2} x^2 + 1 \\tag{18}\n",
        "\\end{align}\n",
        "\n",
        "Then, the derivative $\\Delta f$ will be: <br>\n",
        "\\begin{align}\n",
        "\\Delta f = x^2 - x \\tag{19}\n",
        "\\end{align}\n",
        "\n",
        "At $x=2.125$, using **Eq. 19** we have $\\Delta f = 2.390625$\n",
        "\n",
        "If we calculate the numerical gradient using FDA we have:\n",
        "\\begin{align}\n",
        "\\Delta_{num\\_grad} f = \\frac{f(x + \\epsilon) - f(x - \\epsilon)}{2 * \\epsilon}  \\tag{20}\n",
        "\\end{align}\n",
        "\n",
        "where $\\epsilon$ is a very small value (E.g. $\\epsilon = 1e-{04}$)\n",
        "\n",
        "At the same point $x=2.125$, using **Eq. 15** we have $\\Delta_{num\\_grad} f = 2.3906250033389753$ <br>\n",
        "\n",
        "We can see that, the calculated values of $\\Delta f$ and $\\Delta_{num\\_grad} f$ are very close to each other. <br>\n",
        "\n",
        "With the same idea, we can check the gradient calculation of our network using FDA. A simple way to do this is: <br>\n",
        "1) We wiggle (by a very small $\\epsilon$ values) the value of our weight for all of the parameters in our model. By all parameters, I mean all of the weights of $W_1$, $W_2$ and $W_3$. E.g. if we use 7 neurons in the first hidden layer and 3 neurons in the second hidden layer, the number of parameters in our network is : <br> \n",
        "$num\\_params(net) = num\\_params(W_1) + num\\_params(W_2) + num\\_params(W_3) = 28*28*7 + 7*7*3 + 3*10 = 5665$ <br>\n",
        "so we have to repeat the \"wiggling\" and calculate the numerical gradient 5665 times. At the end, we have a $num\\_grad$ vector that have shape (5665,) <br>\n",
        "2) Calculate the gradient by taking the derivative. Similarly, we will have a $grad$ vector that also have shape (5665,) <br>\n",
        "3) Compare $num\\_grad$ and $grad$ vectors by: <br>\n",
        "\\begin{align}\n",
        "grad\\_diff = \\frac{||grad - num\\_grad||_2}{|grad + num\\_grad|_2}  \\tag{21}\n",
        "\\end{align}\n",
        "\n",
        "If **grad_diff** is smaller than $1e-{08}$ than we assume that our gradient calculation is correct."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOR8lUaZy1E8"
      },
      "source": [
        "### Question: Why don't we use FDA to calculate the gradient to update our model? (<span style=\"color:green\">0.5 points</span>) <br>\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aVA7Ec2y1E8"
      },
      "source": [
        "**Answer:** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbPuB1iny1E8"
      },
      "source": [
        "I think in terms of complexity as  derivative complexty  is simple and fast O(f(x)) and FDA complexity is O(n*f(x)). which shows that FDA would be much slower than derivative thats why it's better to calculate gradient using derivative."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9_Bl3vfy1E8"
      },
      "source": [
        "### Hyper-parameters in your training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLVjOcxNy1E8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e00360d-1b74-4b5c-b4b2-ea72a4ef4382"
      },
      "source": [
        "# Flag use to enable/disable weight decay regularization\n",
        "is_weight_decay = True\n",
        "\n",
        "if is_weight_decay:\n",
        "    # Setting lambda coefficient for weight decay\n",
        "    lmda = np.exp(-7)\n",
        "\n",
        "# Seting learning rate and momentum for SGD\n",
        "learning_rate = 0.25\n",
        "beta = 0.5\n",
        "\n",
        "# Seting the number of training epochs\n",
        "epoch = 50\n",
        "# Choose your batch size\n",
        "batch_size = 128 #128\n",
        "# Calculate the number of training iterations base on the number of training samples and your batch size\n",
        "num_batchs = num_trains // batch_size\n",
        "\n",
        "print(\"Num_trains: {}, num_batchs: {}\".format(num_trains, num_batchs))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num_trains: 60000, num_batchs: 468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuDwIHYGy1E9"
      },
      "source": [
        "### Training your network (<span style=\"color:green\">9.5 points</span>)\n",
        "\n",
        "In this assignment, we will train our model using mini-batch stochatic gradient descent with momentum. To know more about this optimization algorithm, please check out this great [video](https://www.youtube.com/watch?v=k8fTYJPd3_I) from Dr. Andrew Ng. <br>\n",
        "For this assignment, we will use the implementation from **Eq. 22** and **Eq. 23** <br>\n",
        "\n",
        "\\begin{align}\n",
        "v_{dW} = \\beta v_{dW} + (1 - \\beta) dW \\tag{22}\n",
        "\\end{align}\n",
        "\\begin{align}\n",
        "W = W - \\alpha v_{dW} \\tag{23}\n",
        "\\end{align}\n",
        "\n",
        "If you are curious, you can modify the hyper-params in the above section at your will."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2mfWjqtyy1E9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "10c8999c-7e3a-4cd0-9582-db81f50940ad"
      },
      "source": [
        "# Define an interactive ipython figure to display the training loss\n",
        "%matplotlib notebook\n",
        "fig = plt.figure(\"Training loss\")\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "plt.ion()\n",
        "fig.show()\n",
        "fig.canvas.draw()\n",
        "\n",
        "# Log the training loss\n",
        "loss_log = []\n",
        "\n",
        "# Zeros initialize the momentum for SGD\n",
        "V_dW1 = np.zeros(W1.shape)\n",
        "V_dW2 = np.zeros(W2.shape)\n",
        "V_dW3 = np.zeros(W3.shape)\n",
        "\n",
        "# Training\n",
        "for i in range(epoch):\n",
        "    start_t = time.time()\n",
        "    \n",
        "    # Random shuffle training data every training epoch\n",
        "    np.random.seed(np.random.randint(num_trains))\n",
        "    indices = np.random.permutation(num_trains)\n",
        "    X_train_shuffled, Y_train_shuffled = X_train[:, indices], Y_train[:, indices]\n",
        "\n",
        "    for j in range(num_batchs):\n",
        "\n",
        "        # Get mini-batch samples for training\n",
        "        start_idx = j * batch_size\n",
        "        end_idx = min(j * batch_size + batch_size, X_train.shape[1] - 1)\n",
        "        X, Y = X_train_shuffled[:, start_idx : end_idx], Y_train_shuffled[:, start_idx : end_idx]\n",
        "        # Size of actual mini-batch, it could be smaller than batch_size\n",
        "        mini_batch = end_idx - start_idx\n",
        "        \n",
        "        # TODO: implement the forward-pass (1.0 point)\n",
        "        Z1 = np.matmul(W1 , X)\n",
        "        A1 = sigmoid(Z1)\n",
        "        Z2 = np.matmul(W2,A1)\n",
        "        A2 = sigmoid(Z2)\n",
        "        Z3 = np.matmul(W3, A2)\n",
        "        A3 =softmax(Z3)\n",
        "        \n",
        "\n",
        "        if is_weight_decay: \n",
        "            # TODO: call cross entropy loss with weight decay regularization\n",
        "            # We need to penalize both W1, W2 and W3 here with the lmda coefficient defined above\n",
        "            # (0.5 point)\n",
        "            L =cross_entropy_loss(Y,A3) + (lmda/2) * (np.sum(W1 ** 2) + np.sum(W2 ** 2) + np.sum(W3 ** 2))\n",
        "           #print(L)\n",
        "        else:\n",
        "            # TODO: call cross entropy loss (0.5 point)\n",
        "            L =cross_entropy_loss(Y,A3)\n",
        "            #print(L)\n",
        "        # Log the training loss during training\n",
        "        loss_log.append(L)\n",
        "        \n",
        "\n",
        "        # TODO: calculate the derivative of ð¿ with respect to ð‘3 using eq. 10 (1.0 point)\n",
        "        dZ3 = A3 - Y\n",
        "        #print(dZ3)\n",
        "        if is_weight_decay:\n",
        "            # TODO: calculate the derivative of ð¿ with respect to W3 using eq. 7 with weight decay regularization\n",
        "            # We only need penalize and W3 here with the lmda coefficient defined above\n",
        "            # (0.5 point)\n",
        "            dW3 =(1./ mini_batch) * np.matmul(dZ3, A2.T) + lmda * W3\n",
        "           #print(dW3)\n",
        "        else:\n",
        "            # TODO: calculate the derivative of ð¿ with respect to W2 using eq. 7 (0.5 point)\n",
        "            # Hints: consider the mini_batch during the calculation of the gradient\n",
        "            # use np.matmul() and transpose the matrix to fit the dimension\n",
        "            dW3 =  (1./ mini_batch) * np.matmul(dZ3, A2.T)\n",
        "        \n",
        "        \n",
        "        # TODO: calculate the derivative of ð¿ with respect to A2 using eq. 12 (1.0 point)\n",
        "        # Hints: use np.matmul() and transpose the matrix to fit the dimension\n",
        "        dA2 = np.matmul(W3.T, dZ3)\n",
        "        \n",
        "        # TODO: calculate the derivative of ð¿ with respect to Z2 using eq. 12 and eq. 13 (1.0 point)\n",
        "        # Hints: use element-wise multiplication * \n",
        "        dZ2 = dA2 *(A2 *(1-A2))\n",
        "        \n",
        "        if is_weight_decay:\n",
        "            # TODO: calculate the derivative of ð¿ with respect to W2 using eq. 7 with weight decay regularization\n",
        "            # We only need penalize and W1 here with the lmda coefficient defined above\n",
        "            # (0.5 point)\n",
        "            dW2 =(1./ mini_batch) * np.matmul(dZ2, A1.T) + lmda * W2\n",
        "           #print(dW2)\n",
        "        else:\n",
        "            # TODO: calculate the derivative of ð¿ with respect to W2 using eq. 8 (0.5 point)\n",
        "            # Hints: similarly, consider the mini_batch during the calculation of the gradient\n",
        "            # use np.matmul() and transpose the matrix to fit the dimension\n",
        "            dW2 =(1/ mini_batch) * np.matmul(dZ2, A1.T)      \n",
        "            \n",
        "        # TODO: calculate the derivative of ð¿ with respect to A1 using eq. 15 (1.0 point)\n",
        "        # Hints: use np.matmul() and transpose the matrix to fit the dimension\n",
        "        dA1 = np.matmul(W2.T, dZ2)\n",
        "        \n",
        "        # TODO: calculate the derivative of ð¿ with respect to Z1 using eq. 15 and eq. 16 (1.0 point)\n",
        "        # Hints: use element-wise multiplication * \n",
        "        dZ1 =  dA1* (A1*(1-A1))                          #A1 * sigmoid(Z1) * (1 - sigmoid(Z1))\n",
        "         \n",
        "        if is_weight_decay:\n",
        "            # TODO: calculate the derivative of ð¿ with respect to W1 using eq. 9 with weight decay regularization\n",
        "            # We only need penalize and W1 here with the lmda coefficient defined above\n",
        "            # (0.5 point)\n",
        "            dW1 =(1./ mini_batch) * np.matmul(dZ1, X.T) + lmda * W1\n",
        "            #print(dW1)\n",
        "        else:\n",
        "            # TODO: calculate the derivative of ð¿ with respect to W1 using eq. 9 (0.5 point)\n",
        "            # Hints: similarly, consider the mini_batch during the calculation of the gradient\n",
        "            # use np.matmul() and transpose the matrix to fit the dimension\n",
        "            dW1 = (1./ mini_batch) * np.matmul(dZ1, X.T)         \n",
        "        \n",
        "        # TODO: Update the learning velocity using Eq. 22 (1.0 point)\n",
        "        V_dW1 = beta * V_dW1 + (1 - beta) * dW1\n",
        "        V_dW2 = beta * V_dW2 + (1 - beta) * dW2\n",
        "        V_dW3 = beta * V_dW3 + (1 - beta) * dW3\n",
        "\n",
        "        # TODO: Update the model weights using Eq. 23 (1.0 point)\n",
        "        W1 = W1 - learning_rate * V_dW1\n",
        "        W2 = W2 - learning_rate * V_dW2\n",
        "        W3 = W3 - learning_rate * V_dW3\n",
        "\n",
        "        if (j % 100 == 0):\n",
        "            print(\"[Epoch/Iterations]:[{}/{}], loss: {}\".format(i, j, L))\n",
        "            \n",
        "    ax.clear()\n",
        "    ax.plot(loss_log)\n",
        "    fig.canvas.draw()\n",
        "    print(\"=> Elapsed time epoch #{} : {:.2f} seconds\".format(i, time.time() - start_t))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "/* Put everything inside the global mpl namespace */\n",
              "window.mpl = {};\n",
              "\n",
              "\n",
              "mpl.get_websocket_type = function() {\n",
              "    if (typeof(WebSocket) !== 'undefined') {\n",
              "        return WebSocket;\n",
              "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
              "        return MozWebSocket;\n",
              "    } else {\n",
              "        alert('Your browser does not have WebSocket support. ' +\n",
              "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
              "              'Firefox 4 and 5 are also supported but you ' +\n",
              "              'have to enable WebSockets in about:config.');\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
              "    this.id = figure_id;\n",
              "\n",
              "    this.ws = websocket;\n",
              "\n",
              "    this.supports_binary = (this.ws.binaryType != undefined);\n",
              "\n",
              "    if (!this.supports_binary) {\n",
              "        var warnings = document.getElementById(\"mpl-warnings\");\n",
              "        if (warnings) {\n",
              "            warnings.style.display = 'block';\n",
              "            warnings.textContent = (\n",
              "                \"This browser does not support binary websocket messages. \" +\n",
              "                    \"Performance may be slow.\");\n",
              "        }\n",
              "    }\n",
              "\n",
              "    this.imageObj = new Image();\n",
              "\n",
              "    this.context = undefined;\n",
              "    this.message = undefined;\n",
              "    this.canvas = undefined;\n",
              "    this.rubberband_canvas = undefined;\n",
              "    this.rubberband_context = undefined;\n",
              "    this.format_dropdown = undefined;\n",
              "\n",
              "    this.image_mode = 'full';\n",
              "\n",
              "    this.root = $('<div/>');\n",
              "    this._root_extra_style(this.root)\n",
              "    this.root.attr('style', 'display: inline-block');\n",
              "\n",
              "    $(parent_element).append(this.root);\n",
              "\n",
              "    this._init_header(this);\n",
              "    this._init_canvas(this);\n",
              "    this._init_toolbar(this);\n",
              "\n",
              "    var fig = this;\n",
              "\n",
              "    this.waiting = false;\n",
              "\n",
              "    this.ws.onopen =  function () {\n",
              "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
              "            fig.send_message(\"send_image_mode\", {});\n",
              "            if (mpl.ratio != 1) {\n",
              "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
              "            }\n",
              "            fig.send_message(\"refresh\", {});\n",
              "        }\n",
              "\n",
              "    this.imageObj.onload = function() {\n",
              "            if (fig.image_mode == 'full') {\n",
              "                // Full images could contain transparency (where diff images\n",
              "                // almost always do), so we need to clear the canvas so that\n",
              "                // there is no ghosting.\n",
              "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
              "            }\n",
              "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
              "        };\n",
              "\n",
              "    this.imageObj.onunload = function() {\n",
              "        fig.ws.close();\n",
              "    }\n",
              "\n",
              "    this.ws.onmessage = this._make_on_message_function(this);\n",
              "\n",
              "    this.ondownload = ondownload;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_header = function() {\n",
              "    var titlebar = $(\n",
              "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
              "        'ui-helper-clearfix\"/>');\n",
              "    var titletext = $(\n",
              "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
              "        'text-align: center; padding: 3px;\"/>');\n",
              "    titlebar.append(titletext)\n",
              "    this.root.append(titlebar);\n",
              "    this.header = titletext[0];\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_canvas = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var canvas_div = $('<div/>');\n",
              "\n",
              "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
              "\n",
              "    function canvas_keyboard_event(event) {\n",
              "        return fig.key_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
              "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
              "    this.canvas_div = canvas_div\n",
              "    this._canvas_extra_style(canvas_div)\n",
              "    this.root.append(canvas_div);\n",
              "\n",
              "    var canvas = $('<canvas/>');\n",
              "    canvas.addClass('mpl-canvas');\n",
              "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
              "\n",
              "    this.canvas = canvas[0];\n",
              "    this.context = canvas[0].getContext(\"2d\");\n",
              "\n",
              "    var backingStore = this.context.backingStorePixelRatio ||\n",
              "\tthis.context.webkitBackingStorePixelRatio ||\n",
              "\tthis.context.mozBackingStorePixelRatio ||\n",
              "\tthis.context.msBackingStorePixelRatio ||\n",
              "\tthis.context.oBackingStorePixelRatio ||\n",
              "\tthis.context.backingStorePixelRatio || 1;\n",
              "\n",
              "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
              "\n",
              "    var rubberband = $('<canvas/>');\n",
              "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
              "\n",
              "    var pass_mouse_events = true;\n",
              "\n",
              "    canvas_div.resizable({\n",
              "        start: function(event, ui) {\n",
              "            pass_mouse_events = false;\n",
              "        },\n",
              "        resize: function(event, ui) {\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "        stop: function(event, ui) {\n",
              "            pass_mouse_events = true;\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "    });\n",
              "\n",
              "    function mouse_event_fn(event) {\n",
              "        if (pass_mouse_events)\n",
              "            return fig.mouse_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    rubberband.mousedown('button_press', mouse_event_fn);\n",
              "    rubberband.mouseup('button_release', mouse_event_fn);\n",
              "    // Throttle sequential mouse events to 1 every 20ms.\n",
              "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
              "\n",
              "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
              "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
              "\n",
              "    canvas_div.on(\"wheel\", function (event) {\n",
              "        event = event.originalEvent;\n",
              "        event['data'] = 'scroll'\n",
              "        if (event.deltaY < 0) {\n",
              "            event.step = 1;\n",
              "        } else {\n",
              "            event.step = -1;\n",
              "        }\n",
              "        mouse_event_fn(event);\n",
              "    });\n",
              "\n",
              "    canvas_div.append(canvas);\n",
              "    canvas_div.append(rubberband);\n",
              "\n",
              "    this.rubberband = rubberband;\n",
              "    this.rubberband_canvas = rubberband[0];\n",
              "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
              "    this.rubberband_context.strokeStyle = \"#000000\";\n",
              "\n",
              "    this._resize_canvas = function(width, height) {\n",
              "        // Keep the size of the canvas, canvas container, and rubber band\n",
              "        // canvas in synch.\n",
              "        canvas_div.css('width', width)\n",
              "        canvas_div.css('height', height)\n",
              "\n",
              "        canvas.attr('width', width * mpl.ratio);\n",
              "        canvas.attr('height', height * mpl.ratio);\n",
              "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
              "\n",
              "        rubberband.attr('width', width);\n",
              "        rubberband.attr('height', height);\n",
              "    }\n",
              "\n",
              "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
              "    // upon first draw.\n",
              "    this._resize_canvas(600, 600);\n",
              "\n",
              "    // Disable right mouse context menu.\n",
              "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
              "        return false;\n",
              "    });\n",
              "\n",
              "    function set_focus () {\n",
              "        canvas.focus();\n",
              "        canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    window.setTimeout(set_focus, 100);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>');\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items) {\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) {\n",
              "            // put a spacer in here.\n",
              "            continue;\n",
              "        }\n",
              "        var button = $('<button/>');\n",
              "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
              "                        'ui-button-icon-only');\n",
              "        button.attr('role', 'button');\n",
              "        button.attr('aria-disabled', 'false');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "\n",
              "        var icon_img = $('<span/>');\n",
              "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
              "        icon_img.addClass(image);\n",
              "        icon_img.addClass('ui-corner-all');\n",
              "\n",
              "        var tooltip_span = $('<span/>');\n",
              "        tooltip_span.addClass('ui-button-text');\n",
              "        tooltip_span.html(tooltip);\n",
              "\n",
              "        button.append(icon_img);\n",
              "        button.append(tooltip_span);\n",
              "\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    var fmt_picker_span = $('<span/>');\n",
              "\n",
              "    var fmt_picker = $('<select/>');\n",
              "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
              "    fmt_picker_span.append(fmt_picker);\n",
              "    nav_element.append(fmt_picker_span);\n",
              "    this.format_dropdown = fmt_picker[0];\n",
              "\n",
              "    for (var ind in mpl.extensions) {\n",
              "        var fmt = mpl.extensions[ind];\n",
              "        var option = $(\n",
              "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
              "        fmt_picker.append(option);\n",
              "    }\n",
              "\n",
              "    // Add hover states to the ui-buttons\n",
              "    $( \".ui-button\" ).hover(\n",
              "        function() { $(this).addClass(\"ui-state-hover\");},\n",
              "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
              "    );\n",
              "\n",
              "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
              "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
              "    // which will in turn request a refresh of the image.\n",
              "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_message = function(type, properties) {\n",
              "    properties['type'] = type;\n",
              "    properties['figure_id'] = this.id;\n",
              "    this.ws.send(JSON.stringify(properties));\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_draw_message = function() {\n",
              "    if (!this.waiting) {\n",
              "        this.waiting = true;\n",
              "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
              "    }\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    var format_dropdown = fig.format_dropdown;\n",
              "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
              "    fig.ondownload(fig, format);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
              "    var size = msg['size'];\n",
              "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
              "        fig._resize_canvas(size[0], size[1]);\n",
              "        fig.send_message(\"refresh\", {});\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
              "    var x0 = msg['x0'] / mpl.ratio;\n",
              "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
              "    var x1 = msg['x1'] / mpl.ratio;\n",
              "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
              "    x0 = Math.floor(x0) + 0.5;\n",
              "    y0 = Math.floor(y0) + 0.5;\n",
              "    x1 = Math.floor(x1) + 0.5;\n",
              "    y1 = Math.floor(y1) + 0.5;\n",
              "    var min_x = Math.min(x0, x1);\n",
              "    var min_y = Math.min(y0, y1);\n",
              "    var width = Math.abs(x1 - x0);\n",
              "    var height = Math.abs(y1 - y0);\n",
              "\n",
              "    fig.rubberband_context.clearRect(\n",
              "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
              "\n",
              "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
              "    // Updates the figure title.\n",
              "    fig.header.textContent = msg['label'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
              "    var cursor = msg['cursor'];\n",
              "    switch(cursor)\n",
              "    {\n",
              "    case 0:\n",
              "        cursor = 'pointer';\n",
              "        break;\n",
              "    case 1:\n",
              "        cursor = 'default';\n",
              "        break;\n",
              "    case 2:\n",
              "        cursor = 'crosshair';\n",
              "        break;\n",
              "    case 3:\n",
              "        cursor = 'move';\n",
              "        break;\n",
              "    }\n",
              "    fig.rubberband_canvas.style.cursor = cursor;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
              "    fig.message.textContent = msg['message'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
              "    // Request the server to send over a new figure.\n",
              "    fig.send_draw_message();\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
              "    fig.image_mode = msg['mode'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Called whenever the canvas gets updated.\n",
              "    this.send_message(\"ack\", {});\n",
              "}\n",
              "\n",
              "// A function to construct a web socket function for onmessage handling.\n",
              "// Called in the figure constructor.\n",
              "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
              "    return function socket_on_message(evt) {\n",
              "        if (evt.data instanceof Blob) {\n",
              "            /* FIXME: We get \"Resource interpreted as Image but\n",
              "             * transferred with MIME type text/plain:\" errors on\n",
              "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
              "             * to be part of the websocket stream */\n",
              "            evt.data.type = \"image/png\";\n",
              "\n",
              "            /* Free the memory for the previous frames */\n",
              "            if (fig.imageObj.src) {\n",
              "                (window.URL || window.webkitURL).revokeObjectURL(\n",
              "                    fig.imageObj.src);\n",
              "            }\n",
              "\n",
              "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
              "                evt.data);\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
              "            fig.imageObj.src = evt.data;\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        var msg = JSON.parse(evt.data);\n",
              "        var msg_type = msg['type'];\n",
              "\n",
              "        // Call the  \"handle_{type}\" callback, which takes\n",
              "        // the figure and JSON message as its only arguments.\n",
              "        try {\n",
              "            var callback = fig[\"handle_\" + msg_type];\n",
              "        } catch (e) {\n",
              "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        if (callback) {\n",
              "            try {\n",
              "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
              "                callback(fig, msg);\n",
              "            } catch (e) {\n",
              "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
              "            }\n",
              "        }\n",
              "    };\n",
              "}\n",
              "\n",
              "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
              "mpl.findpos = function(e) {\n",
              "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
              "    var targ;\n",
              "    if (!e)\n",
              "        e = window.event;\n",
              "    if (e.target)\n",
              "        targ = e.target;\n",
              "    else if (e.srcElement)\n",
              "        targ = e.srcElement;\n",
              "    if (targ.nodeType == 3) // defeat Safari bug\n",
              "        targ = targ.parentNode;\n",
              "\n",
              "    // jQuery normalizes the pageX and pageY\n",
              "    // pageX,Y are the mouse positions relative to the document\n",
              "    // offset() returns the position of the element relative to the document\n",
              "    var x = e.pageX - $(targ).offset().left;\n",
              "    var y = e.pageY - $(targ).offset().top;\n",
              "\n",
              "    return {\"x\": x, \"y\": y};\n",
              "};\n",
              "\n",
              "/*\n",
              " * return a copy of an object with only non-object keys\n",
              " * we need this to avoid circular references\n",
              " * http://stackoverflow.com/a/24161582/3208463\n",
              " */\n",
              "function simpleKeys (original) {\n",
              "  return Object.keys(original).reduce(function (obj, key) {\n",
              "    if (typeof original[key] !== 'object')\n",
              "        obj[key] = original[key]\n",
              "    return obj;\n",
              "  }, {});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.mouse_event = function(event, name) {\n",
              "    var canvas_pos = mpl.findpos(event)\n",
              "\n",
              "    if (name === 'button_press')\n",
              "    {\n",
              "        this.canvas.focus();\n",
              "        this.canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    var x = canvas_pos.x * mpl.ratio;\n",
              "    var y = canvas_pos.y * mpl.ratio;\n",
              "\n",
              "    this.send_message(name, {x: x, y: y, button: event.button,\n",
              "                             step: event.step,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "\n",
              "    /* This prevents the web browser from automatically changing to\n",
              "     * the text insertion cursor when the button is pressed.  We want\n",
              "     * to control all of the cursor setting manually through the\n",
              "     * 'cursor' event from matplotlib */\n",
              "    event.preventDefault();\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    // Handle any extra behaviour associated with a key event\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.key_event = function(event, name) {\n",
              "\n",
              "    // Prevent repeat events\n",
              "    if (name == 'key_press')\n",
              "    {\n",
              "        if (event.which === this._key)\n",
              "            return;\n",
              "        else\n",
              "            this._key = event.which;\n",
              "    }\n",
              "    if (name == 'key_release')\n",
              "        this._key = null;\n",
              "\n",
              "    var value = '';\n",
              "    if (event.ctrlKey && event.which != 17)\n",
              "        value += \"ctrl+\";\n",
              "    if (event.altKey && event.which != 18)\n",
              "        value += \"alt+\";\n",
              "    if (event.shiftKey && event.which != 16)\n",
              "        value += \"shift+\";\n",
              "\n",
              "    value += 'k';\n",
              "    value += event.which.toString();\n",
              "\n",
              "    this._key_event_extra(event, name);\n",
              "\n",
              "    this.send_message(name, {key: value,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
              "    if (name == 'download') {\n",
              "        this.handle_save(this, null);\n",
              "    } else {\n",
              "        this.send_message(\"toolbar_button\", {name: name});\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
              "    this.message.textContent = tooltip;\n",
              "};\n",
              "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
              "\n",
              "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
              "\n",
              "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
              "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
              "    // object with the appropriate methods. Currently this is a non binary\n",
              "    // socket, so there is still some room for performance tuning.\n",
              "    var ws = {};\n",
              "\n",
              "    ws.close = function() {\n",
              "        comm.close()\n",
              "    };\n",
              "    ws.send = function(m) {\n",
              "        //console.log('sending', m);\n",
              "        comm.send(m);\n",
              "    };\n",
              "    // Register the callback with on_msg.\n",
              "    comm.on_msg(function(msg) {\n",
              "        //console.log('receiving', msg['content']['data'], msg);\n",
              "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
              "        ws.onmessage(msg['content']['data'])\n",
              "    });\n",
              "    return ws;\n",
              "}\n",
              "\n",
              "mpl.mpl_figure_comm = function(comm, msg) {\n",
              "    // This is the function which gets called when the mpl process\n",
              "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
              "\n",
              "    var id = msg.content.data.id;\n",
              "    // Get hold of the div created by the display call when the Comm\n",
              "    // socket was opened in Python.\n",
              "    var element = $(\"#\" + id);\n",
              "    var ws_proxy = comm_websocket_adapter(comm)\n",
              "\n",
              "    function ondownload(figure, format) {\n",
              "        window.open(figure.imageObj.src);\n",
              "    }\n",
              "\n",
              "    var fig = new mpl.figure(id, ws_proxy,\n",
              "                           ondownload,\n",
              "                           element.get(0));\n",
              "\n",
              "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
              "    // web socket which is closed, not our websocket->open comm proxy.\n",
              "    ws_proxy.onopen();\n",
              "\n",
              "    fig.parent_element = element.get(0);\n",
              "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
              "    if (!fig.cell_info) {\n",
              "        console.error(\"Failed to find cell for figure\", id, fig);\n",
              "        return;\n",
              "    }\n",
              "\n",
              "    var output_index = fig.cell_info[2]\n",
              "    var cell = fig.cell_info[0];\n",
              "\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
              "    var width = fig.canvas.width/mpl.ratio\n",
              "    fig.root.unbind('remove')\n",
              "\n",
              "    // Update the output cell to use the data from the current canvas.\n",
              "    fig.push_to_output();\n",
              "    var dataURL = fig.canvas.toDataURL();\n",
              "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
              "    // the notebook keyboard shortcuts fail.\n",
              "    IPython.keyboard_manager.enable()\n",
              "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
              "    fig.close_ws(fig, msg);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.close_ws = function(fig, msg){\n",
              "    fig.send_message('closing', msg);\n",
              "    // fig.ws.close()\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
              "    // Turn the data on the canvas into data in the output cell.\n",
              "    var width = this.canvas.width/mpl.ratio\n",
              "    var dataURL = this.canvas.toDataURL();\n",
              "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Tell IPython that the notebook contents must change.\n",
              "    IPython.notebook.set_dirty(true);\n",
              "    this.send_message(\"ack\", {});\n",
              "    var fig = this;\n",
              "    // Wait a second, then push the new image to the DOM so\n",
              "    // that it is saved nicely (might be nice to debounce this).\n",
              "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>');\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items){\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) { continue; };\n",
              "\n",
              "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    // Add the status bar.\n",
              "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "\n",
              "    // Add the close button to the window.\n",
              "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
              "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
              "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
              "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
              "    buttongrp.append(button);\n",
              "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
              "    titlebar.prepend(buttongrp);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(el){\n",
              "    var fig = this\n",
              "    el.on(\"remove\", function(){\n",
              "\tfig.close_ws(fig, {});\n",
              "    });\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(el){\n",
              "    // this is important to make the div 'focusable\n",
              "    el.attr('tabindex', 0)\n",
              "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
              "    // off when our div gets focus\n",
              "\n",
              "    // location in version 3\n",
              "    if (IPython.notebook.keyboard_manager) {\n",
              "        IPython.notebook.keyboard_manager.register_events(el);\n",
              "    }\n",
              "    else {\n",
              "        // location in version 2\n",
              "        IPython.keyboard_manager.register_events(el);\n",
              "    }\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    var manager = IPython.notebook.keyboard_manager;\n",
              "    if (!manager)\n",
              "        manager = IPython.keyboard_manager;\n",
              "\n",
              "    // Check for shift+enter\n",
              "    if (event.shiftKey && event.which == 13) {\n",
              "        this.canvas_div.blur();\n",
              "        // select the cell after this one\n",
              "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
              "        IPython.notebook.select(index + 1);\n",
              "    }\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    fig.ondownload(fig, null);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.find_output_cell = function(html_output) {\n",
              "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
              "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
              "    // IPython event is triggered only after the cells have been serialised, which for\n",
              "    // our purposes (turning an active figure into a static one), is too late.\n",
              "    var cells = IPython.notebook.get_cells();\n",
              "    var ncells = cells.length;\n",
              "    for (var i=0; i<ncells; i++) {\n",
              "        var cell = cells[i];\n",
              "        if (cell.cell_type === 'code'){\n",
              "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
              "                var data = cell.output_area.outputs[j];\n",
              "                if (data.data) {\n",
              "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
              "                    data = data.data;\n",
              "                }\n",
              "                if (data['text/html'] == html_output) {\n",
              "                    return [cell, data, j];\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "    }\n",
              "}\n",
              "\n",
              "// Register the function which deals with the matplotlib target/channel.\n",
              "// The kernel may be null if the page has been refreshed.\n",
              "if (IPython.notebook.kernel != null) {\n",
              "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
              "}\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id='bdddd503-f994-4a3a-a785-ce6646d1d7df'></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch/Iterations]:[0/0], loss: 3.883207468940046\n",
            "[Epoch/Iterations]:[0/100], loss: 3.8588059064954052\n",
            "[Epoch/Iterations]:[0/200], loss: 3.53120520452541\n",
            "[Epoch/Iterations]:[0/300], loss: 3.577148295033058\n",
            "[Epoch/Iterations]:[0/400], loss: 3.3333608708819598\n",
            "=> Elapsed time epoch #0 : 0.89 seconds\n",
            "[Epoch/Iterations]:[1/0], loss: 3.2082447833710974\n",
            "[Epoch/Iterations]:[1/100], loss: 3.07149790451468\n",
            "[Epoch/Iterations]:[1/200], loss: 3.009339541452725\n",
            "[Epoch/Iterations]:[1/300], loss: 2.813269321105319\n",
            "[Epoch/Iterations]:[1/400], loss: 2.808168358506638\n",
            "=> Elapsed time epoch #1 : 0.84 seconds\n",
            "[Epoch/Iterations]:[2/0], loss: 2.738990149697413\n",
            "[Epoch/Iterations]:[2/100], loss: 2.6271612220798852\n",
            "[Epoch/Iterations]:[2/200], loss: 2.510246016495016\n",
            "[Epoch/Iterations]:[2/300], loss: 2.4829583204507184\n",
            "[Epoch/Iterations]:[2/400], loss: 2.5161625382304753\n",
            "=> Elapsed time epoch #2 : 0.77 seconds\n",
            "[Epoch/Iterations]:[3/0], loss: 2.4017532529942747\n",
            "[Epoch/Iterations]:[3/100], loss: 2.2571991155626936\n",
            "[Epoch/Iterations]:[3/200], loss: 2.273903378607637\n",
            "[Epoch/Iterations]:[3/300], loss: 2.1056392419162\n",
            "[Epoch/Iterations]:[3/400], loss: 2.119060122614196\n",
            "=> Elapsed time epoch #3 : 0.75 seconds\n",
            "[Epoch/Iterations]:[4/0], loss: 2.014551725838511\n",
            "[Epoch/Iterations]:[4/100], loss: 2.001313010271292\n",
            "[Epoch/Iterations]:[4/200], loss: 2.0155392446113187\n",
            "[Epoch/Iterations]:[4/300], loss: 1.9636464088916128\n",
            "[Epoch/Iterations]:[4/400], loss: 1.9326928527408327\n",
            "=> Elapsed time epoch #4 : 0.72 seconds\n",
            "[Epoch/Iterations]:[5/0], loss: 1.802469893466517\n",
            "[Epoch/Iterations]:[5/100], loss: 1.9011078486444175\n",
            "[Epoch/Iterations]:[5/200], loss: 1.7871826755880449\n",
            "[Epoch/Iterations]:[5/300], loss: 1.8097860198709363\n",
            "[Epoch/Iterations]:[5/400], loss: 1.7922522087530375\n",
            "=> Elapsed time epoch #5 : 0.74 seconds\n",
            "[Epoch/Iterations]:[6/0], loss: 1.7184734412613998\n",
            "[Epoch/Iterations]:[6/100], loss: 1.7806645915677364\n",
            "[Epoch/Iterations]:[6/200], loss: 1.6279416773127982\n",
            "[Epoch/Iterations]:[6/300], loss: 1.6035487947290306\n",
            "[Epoch/Iterations]:[6/400], loss: 1.6302735319482753\n",
            "=> Elapsed time epoch #6 : 0.73 seconds\n",
            "[Epoch/Iterations]:[7/0], loss: 1.5514597314547438\n",
            "[Epoch/Iterations]:[7/100], loss: 1.5284707642065212\n",
            "[Epoch/Iterations]:[7/200], loss: 1.4871720441454206\n",
            "[Epoch/Iterations]:[7/300], loss: 1.468931416150674\n",
            "[Epoch/Iterations]:[7/400], loss: 1.514878071341373\n",
            "=> Elapsed time epoch #7 : 0.72 seconds\n",
            "[Epoch/Iterations]:[8/0], loss: 1.474982398908815\n",
            "[Epoch/Iterations]:[8/100], loss: 1.5470838654986854\n",
            "[Epoch/Iterations]:[8/200], loss: 1.3625434704601165\n",
            "[Epoch/Iterations]:[8/300], loss: 1.4048488122623044\n",
            "[Epoch/Iterations]:[8/400], loss: 1.2907191956024633\n",
            "=> Elapsed time epoch #8 : 0.71 seconds\n",
            "[Epoch/Iterations]:[9/0], loss: 1.469843275838123\n",
            "[Epoch/Iterations]:[9/100], loss: 1.294285155679677\n",
            "[Epoch/Iterations]:[9/200], loss: 1.2887418412396525\n",
            "[Epoch/Iterations]:[9/300], loss: 1.228294527976051\n",
            "[Epoch/Iterations]:[9/400], loss: 1.2490435607158576\n",
            "=> Elapsed time epoch #9 : 0.75 seconds\n",
            "[Epoch/Iterations]:[10/0], loss: 1.3484898201994167\n",
            "[Epoch/Iterations]:[10/100], loss: 1.3140890621762984\n",
            "[Epoch/Iterations]:[10/200], loss: 1.3497859747854908\n",
            "[Epoch/Iterations]:[10/300], loss: 1.2725851306451492\n",
            "[Epoch/Iterations]:[10/400], loss: 1.1973027679429349\n",
            "=> Elapsed time epoch #10 : 0.72 seconds\n",
            "[Epoch/Iterations]:[11/0], loss: 1.2119359960275038\n",
            "[Epoch/Iterations]:[11/100], loss: 1.205387282589291\n",
            "[Epoch/Iterations]:[11/200], loss: 1.2444656172408535\n",
            "[Epoch/Iterations]:[11/300], loss: 1.1976852045109396\n",
            "[Epoch/Iterations]:[11/400], loss: 1.2215229650852952\n",
            "=> Elapsed time epoch #11 : 0.77 seconds\n",
            "[Epoch/Iterations]:[12/0], loss: 1.1308710812698377\n",
            "[Epoch/Iterations]:[12/100], loss: 1.1452310846957119\n",
            "[Epoch/Iterations]:[12/200], loss: 1.1824297261687229\n",
            "[Epoch/Iterations]:[12/300], loss: 1.1986787977390165\n",
            "[Epoch/Iterations]:[12/400], loss: 1.200478045929902\n",
            "=> Elapsed time epoch #12 : 0.72 seconds\n",
            "[Epoch/Iterations]:[13/0], loss: 1.1981789588721312\n",
            "[Epoch/Iterations]:[13/100], loss: 1.1337279179647455\n",
            "[Epoch/Iterations]:[13/200], loss: 1.1565775681350268\n",
            "[Epoch/Iterations]:[13/300], loss: 1.1176195773333433\n",
            "[Epoch/Iterations]:[13/400], loss: 1.1846398572301\n",
            "=> Elapsed time epoch #13 : 0.75 seconds\n",
            "[Epoch/Iterations]:[14/0], loss: 1.2499125981743735\n",
            "[Epoch/Iterations]:[14/100], loss: 1.1606514484924326\n",
            "[Epoch/Iterations]:[14/200], loss: 1.1573277707847842\n",
            "[Epoch/Iterations]:[14/300], loss: 1.1591729309181455\n",
            "[Epoch/Iterations]:[14/400], loss: 1.1032017636259306\n",
            "=> Elapsed time epoch #14 : 0.72 seconds\n",
            "[Epoch/Iterations]:[15/0], loss: 1.1260615543217454\n",
            "[Epoch/Iterations]:[15/100], loss: 1.0669986825197286\n",
            "[Epoch/Iterations]:[15/200], loss: 1.1406930211401651\n",
            "[Epoch/Iterations]:[15/300], loss: 1.1156601711037535\n",
            "[Epoch/Iterations]:[15/400], loss: 1.1325846053358444\n",
            "=> Elapsed time epoch #15 : 0.73 seconds\n",
            "[Epoch/Iterations]:[16/0], loss: 0.9969599142083176\n",
            "[Epoch/Iterations]:[16/100], loss: 1.1507554843618042\n",
            "[Epoch/Iterations]:[16/200], loss: 1.0345913865929384\n",
            "[Epoch/Iterations]:[16/300], loss: 1.0585309789154702\n",
            "[Epoch/Iterations]:[16/400], loss: 1.0233799534309918\n",
            "=> Elapsed time epoch #16 : 0.78 seconds\n",
            "[Epoch/Iterations]:[17/0], loss: 1.115830450998797\n",
            "[Epoch/Iterations]:[17/100], loss: 1.1003902571873758\n",
            "[Epoch/Iterations]:[17/200], loss: 1.060941718369019\n",
            "[Epoch/Iterations]:[17/300], loss: 1.091228214848693\n",
            "[Epoch/Iterations]:[17/400], loss: 1.0483858226452658\n",
            "=> Elapsed time epoch #17 : 0.89 seconds\n",
            "[Epoch/Iterations]:[18/0], loss: 1.0860813810398282\n",
            "[Epoch/Iterations]:[18/100], loss: 1.0416329379541174\n",
            "[Epoch/Iterations]:[18/200], loss: 1.0191495168883193\n",
            "[Epoch/Iterations]:[18/300], loss: 1.148773001219925\n",
            "[Epoch/Iterations]:[18/400], loss: 1.0374813406313195\n",
            "=> Elapsed time epoch #18 : 0.87 seconds\n",
            "[Epoch/Iterations]:[19/0], loss: 1.068405120084841\n",
            "[Epoch/Iterations]:[19/100], loss: 1.1873021987173202\n",
            "[Epoch/Iterations]:[19/200], loss: 1.0060859368087571\n",
            "[Epoch/Iterations]:[19/300], loss: 1.0272977962049676\n",
            "[Epoch/Iterations]:[19/400], loss: 1.0223048608659262\n",
            "=> Elapsed time epoch #19 : 0.85 seconds\n",
            "[Epoch/Iterations]:[20/0], loss: 1.1380704846485732\n",
            "[Epoch/Iterations]:[20/100], loss: 0.9818977679071306\n",
            "[Epoch/Iterations]:[20/200], loss: 1.0234969782767833\n",
            "[Epoch/Iterations]:[20/300], loss: 1.0417230464238745\n",
            "[Epoch/Iterations]:[20/400], loss: 1.0034317004015725\n",
            "=> Elapsed time epoch #20 : 0.87 seconds\n",
            "[Epoch/Iterations]:[21/0], loss: 0.9367327693139273\n",
            "[Epoch/Iterations]:[21/100], loss: 1.0204124516732271\n",
            "[Epoch/Iterations]:[21/200], loss: 1.0751316350442515\n",
            "[Epoch/Iterations]:[21/300], loss: 1.0254718193282792\n",
            "[Epoch/Iterations]:[21/400], loss: 0.9848901159395165\n",
            "=> Elapsed time epoch #21 : 0.80 seconds\n",
            "[Epoch/Iterations]:[22/0], loss: 0.9879195898994068\n",
            "[Epoch/Iterations]:[22/100], loss: 1.049171363145601\n",
            "[Epoch/Iterations]:[22/200], loss: 1.08414124098489\n",
            "[Epoch/Iterations]:[22/300], loss: 1.0196694071769583\n",
            "[Epoch/Iterations]:[22/400], loss: 1.0618728795826573\n",
            "=> Elapsed time epoch #22 : 0.79 seconds\n",
            "[Epoch/Iterations]:[23/0], loss: 1.0306767233631304\n",
            "[Epoch/Iterations]:[23/100], loss: 1.0099788685869575\n",
            "[Epoch/Iterations]:[23/200], loss: 1.2151656803518844\n",
            "[Epoch/Iterations]:[23/300], loss: 1.000370811479595\n",
            "[Epoch/Iterations]:[23/400], loss: 1.0437338574641728\n",
            "=> Elapsed time epoch #23 : 0.86 seconds\n",
            "[Epoch/Iterations]:[24/0], loss: 1.088768132590461\n",
            "[Epoch/Iterations]:[24/100], loss: 0.9783420932150864\n",
            "[Epoch/Iterations]:[24/200], loss: 0.9655848810053943\n",
            "[Epoch/Iterations]:[24/300], loss: 0.9772588494360825\n",
            "[Epoch/Iterations]:[24/400], loss: 1.0120970121337824\n",
            "=> Elapsed time epoch #24 : 0.92 seconds\n",
            "[Epoch/Iterations]:[25/0], loss: 0.9221889629435053\n",
            "[Epoch/Iterations]:[25/100], loss: 0.9950927598813324\n",
            "[Epoch/Iterations]:[25/200], loss: 1.0125103372385085\n",
            "[Epoch/Iterations]:[25/300], loss: 0.9323731237872608\n",
            "[Epoch/Iterations]:[25/400], loss: 0.939391737205133\n",
            "=> Elapsed time epoch #25 : 0.76 seconds\n",
            "[Epoch/Iterations]:[26/0], loss: 1.0551381454994098\n",
            "[Epoch/Iterations]:[26/100], loss: 1.003832485022229\n",
            "[Epoch/Iterations]:[26/200], loss: 1.1771745182916244\n",
            "[Epoch/Iterations]:[26/300], loss: 1.0456575667515784\n",
            "[Epoch/Iterations]:[26/400], loss: 1.0900507215778665\n",
            "=> Elapsed time epoch #26 : 0.79 seconds\n",
            "[Epoch/Iterations]:[27/0], loss: 1.0331414558227778\n",
            "[Epoch/Iterations]:[27/100], loss: 1.0687832627869296\n",
            "[Epoch/Iterations]:[27/200], loss: 1.0027087456958712\n",
            "[Epoch/Iterations]:[27/300], loss: 1.1344373264003291\n",
            "[Epoch/Iterations]:[27/400], loss: 1.020372961275362\n",
            "=> Elapsed time epoch #27 : 0.87 seconds\n",
            "[Epoch/Iterations]:[28/0], loss: 1.0345668370069332\n",
            "[Epoch/Iterations]:[28/100], loss: 0.997134750465531\n",
            "[Epoch/Iterations]:[28/200], loss: 1.0891343606316903\n",
            "[Epoch/Iterations]:[28/300], loss: 1.0210630207041216\n",
            "[Epoch/Iterations]:[28/400], loss: 1.082718075013001\n",
            "=> Elapsed time epoch #28 : 0.89 seconds\n",
            "[Epoch/Iterations]:[29/0], loss: 0.8877702922001187\n",
            "[Epoch/Iterations]:[29/100], loss: 1.0839662715494636\n",
            "[Epoch/Iterations]:[29/200], loss: 1.0865206198294945\n",
            "[Epoch/Iterations]:[29/300], loss: 1.064119470095422\n",
            "[Epoch/Iterations]:[29/400], loss: 0.9576179339903876\n",
            "=> Elapsed time epoch #29 : 0.88 seconds\n",
            "[Epoch/Iterations]:[30/0], loss: 1.0802482226700376\n",
            "[Epoch/Iterations]:[30/100], loss: 0.9500160142011296\n",
            "[Epoch/Iterations]:[30/200], loss: 1.0996423060564802\n",
            "[Epoch/Iterations]:[30/300], loss: 0.9587415535248989\n",
            "[Epoch/Iterations]:[30/400], loss: 1.0238821150220734\n",
            "=> Elapsed time epoch #30 : 0.74 seconds\n",
            "[Epoch/Iterations]:[31/0], loss: 1.072629590957249\n",
            "[Epoch/Iterations]:[31/100], loss: 1.0677904755066348\n",
            "[Epoch/Iterations]:[31/200], loss: 0.9505139516634296\n",
            "[Epoch/Iterations]:[31/300], loss: 1.0307489328647426\n",
            "[Epoch/Iterations]:[31/400], loss: 1.0341587202565337\n",
            "=> Elapsed time epoch #31 : 0.74 seconds\n",
            "[Epoch/Iterations]:[32/0], loss: 1.0041280133765793\n",
            "[Epoch/Iterations]:[32/100], loss: 1.0685403341888224\n",
            "[Epoch/Iterations]:[32/200], loss: 1.0824722580582309\n",
            "[Epoch/Iterations]:[32/300], loss: 1.0849086398520043\n",
            "[Epoch/Iterations]:[32/400], loss: 1.0596734716968528\n",
            "=> Elapsed time epoch #32 : 0.80 seconds\n",
            "[Epoch/Iterations]:[33/0], loss: 1.0282926801094987\n",
            "[Epoch/Iterations]:[33/100], loss: 0.967509536192382\n",
            "[Epoch/Iterations]:[33/200], loss: 0.9701990199680419\n",
            "[Epoch/Iterations]:[33/300], loss: 1.0597311950849986\n",
            "[Epoch/Iterations]:[33/400], loss: 0.9798087836115672\n",
            "=> Elapsed time epoch #33 : 0.85 seconds\n",
            "[Epoch/Iterations]:[34/0], loss: 0.9904889735046445\n",
            "[Epoch/Iterations]:[34/100], loss: 1.211900127550855\n",
            "[Epoch/Iterations]:[34/200], loss: 0.9935152478331747\n",
            "[Epoch/Iterations]:[34/300], loss: 0.9377360885904977\n",
            "[Epoch/Iterations]:[34/400], loss: 0.9266104321823638\n",
            "=> Elapsed time epoch #34 : 0.76 seconds\n",
            "[Epoch/Iterations]:[35/0], loss: 0.8636077666709145\n",
            "[Epoch/Iterations]:[35/100], loss: 0.9422568911416362\n",
            "[Epoch/Iterations]:[35/200], loss: 1.061097846207072\n",
            "[Epoch/Iterations]:[35/300], loss: 1.0096261894984306\n",
            "[Epoch/Iterations]:[35/400], loss: 1.0879579605336651\n",
            "=> Elapsed time epoch #35 : 0.73 seconds\n",
            "[Epoch/Iterations]:[36/0], loss: 1.0862391724614882\n",
            "[Epoch/Iterations]:[36/100], loss: 1.0118856864631263\n",
            "[Epoch/Iterations]:[36/200], loss: 0.9351085883731842\n",
            "[Epoch/Iterations]:[36/300], loss: 1.070074684871647\n",
            "[Epoch/Iterations]:[36/400], loss: 0.9579052857991205\n",
            "=> Elapsed time epoch #36 : 0.76 seconds\n",
            "[Epoch/Iterations]:[37/0], loss: 1.0011859108257115\n",
            "[Epoch/Iterations]:[37/100], loss: 1.007356606282092\n",
            "[Epoch/Iterations]:[37/200], loss: 1.0274313321183706\n",
            "[Epoch/Iterations]:[37/300], loss: 1.0489621447064534\n",
            "[Epoch/Iterations]:[37/400], loss: 0.9715268632011302\n",
            "=> Elapsed time epoch #37 : 0.78 seconds\n",
            "[Epoch/Iterations]:[38/0], loss: 0.9810342774390339\n",
            "[Epoch/Iterations]:[38/100], loss: 1.0246788821371848\n",
            "[Epoch/Iterations]:[38/200], loss: 1.0798363765148347\n",
            "[Epoch/Iterations]:[38/300], loss: 0.9689350100498155\n",
            "[Epoch/Iterations]:[38/400], loss: 1.0948166378183928\n",
            "=> Elapsed time epoch #38 : 0.88 seconds\n",
            "[Epoch/Iterations]:[39/0], loss: 1.0362922558030196\n",
            "[Epoch/Iterations]:[39/100], loss: 1.0950170048346124\n",
            "[Epoch/Iterations]:[39/200], loss: 0.9826142977520649\n",
            "[Epoch/Iterations]:[39/300], loss: 1.024030627364882\n",
            "[Epoch/Iterations]:[39/400], loss: 0.9543546585745994\n",
            "=> Elapsed time epoch #39 : 0.89 seconds\n",
            "[Epoch/Iterations]:[40/0], loss: 0.9621969111785719\n",
            "[Epoch/Iterations]:[40/100], loss: 0.9946307080377137\n",
            "[Epoch/Iterations]:[40/200], loss: 1.0708029155359353\n",
            "[Epoch/Iterations]:[40/300], loss: 0.9419629099680034\n",
            "[Epoch/Iterations]:[40/400], loss: 0.9721016264866944\n",
            "=> Elapsed time epoch #40 : 0.79 seconds\n",
            "[Epoch/Iterations]:[41/0], loss: 1.0808508227421307\n",
            "[Epoch/Iterations]:[41/100], loss: 0.9706978202127338\n",
            "[Epoch/Iterations]:[41/200], loss: 0.9612351335141893\n",
            "[Epoch/Iterations]:[41/300], loss: 0.9872392478227972\n",
            "[Epoch/Iterations]:[41/400], loss: 1.065553723096047\n",
            "=> Elapsed time epoch #41 : 0.80 seconds\n",
            "[Epoch/Iterations]:[42/0], loss: 1.074675444895942\n",
            "[Epoch/Iterations]:[42/100], loss: 1.0178725858706084\n",
            "[Epoch/Iterations]:[42/200], loss: 0.982668131552592\n",
            "[Epoch/Iterations]:[42/300], loss: 0.966307237087807\n",
            "[Epoch/Iterations]:[42/400], loss: 0.9945620686245753\n",
            "=> Elapsed time epoch #42 : 0.87 seconds\n",
            "[Epoch/Iterations]:[43/0], loss: 0.9892265693873952\n",
            "[Epoch/Iterations]:[43/100], loss: 1.011190837746576\n",
            "[Epoch/Iterations]:[43/200], loss: 0.9918653359757503\n",
            "[Epoch/Iterations]:[43/300], loss: 1.05805026714355\n",
            "[Epoch/Iterations]:[43/400], loss: 0.9139673604307528\n",
            "=> Elapsed time epoch #43 : 0.77 seconds\n",
            "[Epoch/Iterations]:[44/0], loss: 1.0265850518074087\n",
            "[Epoch/Iterations]:[44/100], loss: 0.9192500765025932\n",
            "[Epoch/Iterations]:[44/200], loss: 1.0420464476272953\n",
            "[Epoch/Iterations]:[44/300], loss: 1.0266388713278507\n",
            "[Epoch/Iterations]:[44/400], loss: 1.013627438728492\n",
            "=> Elapsed time epoch #44 : 0.75 seconds\n",
            "[Epoch/Iterations]:[45/0], loss: 1.1137264963649822\n",
            "[Epoch/Iterations]:[45/100], loss: 1.0469947972294988\n",
            "[Epoch/Iterations]:[45/200], loss: 1.0889492527893965\n",
            "[Epoch/Iterations]:[45/300], loss: 1.0137762633139678\n",
            "[Epoch/Iterations]:[45/400], loss: 0.968717627319778\n",
            "=> Elapsed time epoch #45 : 0.73 seconds\n",
            "[Epoch/Iterations]:[46/0], loss: 1.0307413851848497\n",
            "[Epoch/Iterations]:[46/100], loss: 1.0503928657353676\n",
            "[Epoch/Iterations]:[46/200], loss: 1.1482599458297653\n",
            "[Epoch/Iterations]:[46/300], loss: 0.9117287260244764\n",
            "[Epoch/Iterations]:[46/400], loss: 1.0422417256660987\n",
            "=> Elapsed time epoch #46 : 0.76 seconds\n",
            "[Epoch/Iterations]:[47/0], loss: 0.9702837088294982\n",
            "[Epoch/Iterations]:[47/100], loss: 0.9837350403446462\n",
            "[Epoch/Iterations]:[47/200], loss: 0.9944017804035985\n",
            "[Epoch/Iterations]:[47/300], loss: 1.1237897479138714\n",
            "[Epoch/Iterations]:[47/400], loss: 0.926452674885679\n",
            "=> Elapsed time epoch #47 : 0.76 seconds\n",
            "[Epoch/Iterations]:[48/0], loss: 1.0788711640779014\n",
            "[Epoch/Iterations]:[48/100], loss: 1.018433494130751\n",
            "[Epoch/Iterations]:[48/200], loss: 1.1556304205129688\n",
            "[Epoch/Iterations]:[48/300], loss: 0.9805369583813284\n",
            "[Epoch/Iterations]:[48/400], loss: 1.0967183597185923\n",
            "=> Elapsed time epoch #48 : 0.75 seconds\n",
            "[Epoch/Iterations]:[49/0], loss: 0.9953033980359216\n",
            "[Epoch/Iterations]:[49/100], loss: 0.9523617929100351\n",
            "[Epoch/Iterations]:[49/200], loss: 0.9889239832675948\n",
            "[Epoch/Iterations]:[49/300], loss: 1.0646250613910042\n",
            "[Epoch/Iterations]:[49/400], loss: 0.9828697230731911\n",
            "=> Elapsed time epoch #49 : 0.76 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KDqNbx1sFmx"
      },
      "source": [
        "ax.plot(loss_log)\n",
        "fig.canvas.draw()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x6PrZfyy1E9"
      },
      "source": [
        "### Evaluate the performance of your model (<span style=\"color:green\">0.5 points</span>)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKca1tmky1E-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa2caa5-fd25-43a5-f78f-83acecea14eb"
      },
      "source": [
        "#With 150 and 250 neurons\n",
        "# TODO: implement the forward-pass (0.5 point)\n",
        "# Hints: note that this is similar but not exactly the same as the forward pass during training\n",
        "Z1 = np.matmul(W1, X_test)\n",
        "A1 = sigmoid(Z1)\n",
        "Z2 = np.matmul(W2, A1)\n",
        "A2 = sigmoid(Z2)\n",
        "Z3 = np.matmul(W3, A2)\n",
        "A3 = softmax(Z3)\n",
        "\n",
        "# Evaluate the performance of your NN\n",
        "predictions = np.argmax(A3, axis=0)\n",
        "labels = np.argmax(Y_test, axis=0)\n",
        "print(\"Confusion matrix:\\n{}\".format(confusion_matrix(labels, predictions)))\n",
        "print(\"Testing accuracy: {}\".format(accuracy_score(labels, predictions)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            "[[865   4  18  22   6   2  66   0  17   0]\n",
            " [  6 959   2  23   5   0   1   0   4   0]\n",
            " [ 25   1 778  13 112   0  60   1  10   0]\n",
            " [ 55  16  19 840  41   0  23   0   6   0]\n",
            " [  3   2 118  29 777   1  61   0   9   0]\n",
            " [  1   0   1   1   0 928   1  40   3  25]\n",
            " [218   7 118  23  99   1 509   0  25   0]\n",
            " [  0   0   0   0   0  35   0 938   0  27]\n",
            " [ 10   0   5   4   6   6  13   5 950   1]\n",
            " [  1   0   0   0   0  16   1  50   2 930]]\n",
            "Testing accuracy: 0.8474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMb9rsGrUZqI"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuHl0oU7UaPY",
        "outputId": "c0be6960-4dc1-4a5a-b36f-582c19fbda72"
      },
      "source": [
        "#For is_weight_decay = True\n",
        "# TODO: implement the forward-pass (0.5 point)\n",
        "# Hints: note that this is similar but not exactly the same as the forward pass during training\n",
        "Z1 = np.matmul(W1, X_test)\n",
        "A1 = sigmoid(Z1)\n",
        "Z2 = np.matmul(W2, A1)\n",
        "A2 = sigmoid(Z2)\n",
        "Z3 = np.matmul(W3, A2)\n",
        "A3 = softmax(Z3)\n",
        "\n",
        "# Evaluate the performance of your NN\n",
        "predictions = np.argmax(A3, axis=0)\n",
        "labels = np.argmax(Y_test, axis=0)\n",
        "print(\"Confusion matrix:\\n{}\".format(confusion_matrix(labels, predictions)))\n",
        "print(\"Testing accuracy: {}\".format(accuracy_score(labels, predictions)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            "[[820   4  11  96   4   3  51   0  11   0]\n",
            " [  4 949   1  34   3   0   7   0   2   0]\n",
            " [ 21   1 267  20 615   0  71   0   5   0]\n",
            " [ 35  18   8 870  37   2  29   0   1   0]\n",
            " [  1   0 232  43 687   0  34   0   3   0]\n",
            " [  0   0   0   1   0 857   0  67   6  69]\n",
            " [235   1 200  68 122   0 352   0  22   0]\n",
            " [  0   0   0   0   0  19   0 934   1  46]\n",
            " [  9   1  14   3   2   7  34   6 924   0]\n",
            " [  0   1   0   0   0   3   0  47   1 948]]\n",
            "Testing accuracy: 0.7608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v6vfCmNL0Lo"
      },
      "source": [
        "#after changing lr and epochs and other parameters for 24 hr there was no imporvement but after changing neurons the accuracy jumped to 0.84."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXYpQjP7v9HF",
        "outputId": "7ca0418e-70ee-4ab0-df0d-59361398772e"
      },
      "source": [
        "#With 7 and 3 neurons\n",
        "# TODO: implement the forward-pass (0.5 point)\n",
        "# Hints: note that this is similar but not exactly the same as the forward pass during training\n",
        "Z1 = np.matmul(W1, X_test)\n",
        "A1 = sigmoid(Z1)\n",
        "Z2 = np.matmul(W2, A1)\n",
        "A2 = sigmoid(Z2)\n",
        "Z3 = np.matmul(W3, A2)\n",
        "A3 = softmax(Z3)\n",
        "\n",
        "# Evaluate the performance of your NN\n",
        "predictions = np.argmax(A3, axis=0)\n",
        "labels = np.argmax(Y_test, axis=0)\n",
        "print(\"Confusion matrix:\\n{}\".format(confusion_matrix(labels, predictions)))\n",
        "print(\"Testing accuracy: {}\".format(accuracy_score(labels, predictions)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            "[[880   8   2  40  25   4  17   1  23   0]\n",
            " [ 16 951   0  24   5   0   1   0   2   1]\n",
            " [ 40   1  28   5 881   1  25   0  19   0]\n",
            " [266  39   1 614  37   7  28   0   8   0]\n",
            " [ 52   1  24   8 871   0  30   0  14   0]\n",
            " [  0   0   0   1   0 822   0  54  38  85]\n",
            " [318   1  38  18 536   2  42   0  45   0]\n",
            " [  0   0   0   0   0  29   0 923   3  45]\n",
            " [  3   1   3   4   6  15   9   9 950   0]\n",
            " [  0   0   0   0   0  34   0  69   2 895]]\n",
            "Testing accuracy: 0.6976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEJZJ8ouy1E-"
      },
      "source": [
        "## Part 4. Regularization and NN simple tunning (<span style=\"color:green\">2.5 points</span>)\n",
        "\n",
        "1. Applying weight decay (<span style=\"color:green\">1.5 point</span> )\n",
        "  * Using what you learnt from assignment 1 to add the code at neccesary parts in **Training your network** above.\n",
        "  * There are 3 spots, (<span style=\"color:green\">0.5 point</span>) each spot. Insert the answers in above section.\n",
        "2. Change the number of neurons in the hidden layer and report the performance (<span style=\"color:green\">1 point</span>)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgf1mt4UNVwc"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfPzUt-JNWQv",
        "outputId": "2aa2caa5-fd25-43a5-f78f-83acecea14eb"
      },
      "source": [
        "# TODO: implement the forward-pass (0.5 point)\n",
        "# Hints: note that this is similar but not exactly the same as the forward pass during training\n",
        "Z1 = np.matmul(W1, X_test)\n",
        "A1 = sigmoid(Z1)\n",
        "Z2 = np.matmul(W2, A1)\n",
        "A2 = sigmoid(Z2)\n",
        "Z3 = np.matmul(W3, A2)\n",
        "A3 = softmax(Z3)\n",
        "\n",
        "# Evaluate the performance of your NN\n",
        "predictions = np.argmax(A3, axis=0)\n",
        "labels = np.argmax(Y_test, axis=0)\n",
        "print(\"Confusion matrix:\\n{}\".format(confusion_matrix(labels, predictions)))\n",
        "print(\"Testing accuracy: {}\".format(accuracy_score(labels, predictions)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            "[[865   4  18  22   6   2  66   0  17   0]\n",
            " [  6 959   2  23   5   0   1   0   4   0]\n",
            " [ 25   1 778  13 112   0  60   1  10   0]\n",
            " [ 55  16  19 840  41   0  23   0   6   0]\n",
            " [  3   2 118  29 777   1  61   0   9   0]\n",
            " [  1   0   1   1   0 928   1  40   3  25]\n",
            " [218   7 118  23  99   1 509   0  25   0]\n",
            " [  0   0   0   0   0  35   0 938   0  27]\n",
            " [ 10   0   5   4   6   6  13   5 950   1]\n",
            " [  1   0   0   0   0  16   1  50   2 930]]\n",
            "Testing accuracy: 0.8474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK4HJkb3y1E-"
      },
      "source": [
        "**Answer of question 2:**\n",
        "\n",
        "The accuracy of base model was 0.6976 approx 70% but after changing the number of neurons to hidden_layer_1= 150, hidden_layer_2 =250 and it jump to 0.8474 aproxi 85%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02_7fNBHUljB"
      },
      "source": [
        "Results\n",
        "With hidden_layer_1 = 7 and hiddn_layer_2=3 , Accuracy = 0.6976\n",
        "With is_weight_decay_true it is 0.7608\n",
        "With hidden_layer_1 = 150 and hiddn_layer_2=250 , Accuracy = 0.8474"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFRJLjIyy1E-"
      },
      "source": []
    }
  ]
}